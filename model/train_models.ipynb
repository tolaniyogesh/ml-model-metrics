{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Classification Models\n",
    "## Breast Cancer Wisconsin Dataset\n",
    "\n",
    "This notebook trains 6 classification models and evaluates them using multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit==1.31.0 (from -r ../requirements.txt (line 1))\n",
      "  Using cached streamlit-1.31.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting scikit-learn==1.4.0 (from -r ../requirements.txt (line 2))\n",
      "  Using cached scikit-learn-1.4.0.tar.gz (7.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy==1.24.3 (from -r ../requirements.txt (line 3))\n",
      "  Using cached numpy-1.24.3.tar.gz (10.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [32 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m137\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          backend = _build_backend()\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m70\u001b[0m, in \u001b[35m_build_backend\u001b[0m\n",
      "          obj = import_module(mod_path)\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\importlib\\__init__.py\"\u001b[0m, line \u001b[35m88\u001b[0m, in \u001b[35mimport_module\u001b[0m\n",
      "          return \u001b[31m_bootstrap._gcd_import\u001b[0m\u001b[1;31m(name[level:], package, level)\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1387\u001b[0m, in \u001b[35m_gcd_import\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1360\u001b[0m, in \u001b[35m_find_and_load\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1310\u001b[0m, in \u001b[35m_find_and_load_unlocked\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m488\u001b[0m, in \u001b[35m_call_with_frames_removed\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1387\u001b[0m, in \u001b[35m_gcd_import\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1360\u001b[0m, in \u001b[35m_find_and_load\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m1331\u001b[0m, in \u001b[35m_find_and_load_unlocked\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m935\u001b[0m, in \u001b[35m_load_unlocked\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[35m1026\u001b[0m, in \u001b[35mexec_module\u001b[0m\n",
      "        File \u001b[35m\"<frozen importlib._bootstrap>\"\u001b[0m, line \u001b[35m488\u001b[0m, in \u001b[35m_call_with_frames_removed\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Temp\\pip-build-env-680zb035\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\"\u001b[0m, line \u001b[35m16\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          import setuptools.version\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Temp\\pip-build-env-680zb035\\overlay\\Lib\\site-packages\\setuptools\\version.py\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          import pkg_resources\n",
      "        File \u001b[35m\"C:\\Users\\yogesh.tolani\\AppData\\Local\\Temp\\pip-build-env-680zb035\\overlay\\Lib\\site-packages\\pkg_resources\\__init__.py\"\u001b[0m, line \u001b[35m2172\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          register_finder(\u001b[1;31mpkgutil.ImpImporter\u001b[0m, find_on_path)\n",
      "                          \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mAttributeError\u001b[0m: \u001b[35mmodule 'pkgutil' has no attribute 'ImpImporter'. Did you mean: 'zipimporter'?\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "ERROR: Failed to build 'numpy' when getting requirements to build wheel\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, \n",
    "    recall_score, f1_score, matthews_corrcoef,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (569, 30)\n",
      "Number of Features: 30\n",
      "Number of Instances: 569\n",
      "\n",
      "Target Distribution:\n",
      "target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature Names:\n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "print(f\"Dataset Shape: {X.shape}\")\n",
    "print(f\"Number of Features: {X.shape[1]}\")\n",
    "print(f\"Number of Instances: {X.shape[0]}\")\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nFeature Names:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (455, 30)\n",
      "Test set: (114, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV files:\n",
      "- train_data.csv (with target labels)\n",
      "- test_data.csv (with target labels)\n",
      "- test_data_without_labels.csv (for predictions only)\n"
     ]
    }
   ],
   "source": [
    "train_data = X_train.copy()\n",
    "train_data['target'] = y_train.values\n",
    "train_data.to_csv('../train_data.csv', index=False)\n",
    "\n",
    "test_data = X_test.copy()\n",
    "test_data['target'] = y_test.values\n",
    "test_data.to_csv('../test_data.csv', index=False)\n",
    "\n",
    "X_test.to_csv('../test_data_without_labels.csv', index=False)\n",
    "\n",
    "print(\"Saved CSV files:\")\n",
    "print(\"- train_data.csv (with target labels)\")\n",
    "print(\"- test_data.csv (with target labels)\")\n",
    "print(\"- test_data_without_labels.csv (for predictions only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Scaler saved to scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, y_true, y_pred, y_pred_proba=None):\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "        'F1': f1_score(y_true, y_pred, average='binary', zero_division=0),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        try:\n",
    "            metrics['AUC'] = roc_auc_score(y_true, y_pred_proba)\n",
    "        except:\n",
    "            metrics['AUC'] = 0.0\n",
    "    else:\n",
    "        metrics['AUC'] = 0.0\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Models and Evaluate\n",
    "\n",
    "### 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9825\n",
      "Precision: 0.9861\n",
      "Recall: 0.9861\n",
      "F1: 0.9861\n",
      "MCC: 0.9623\n",
      "AUC: 0.9954\n",
      "\n",
      "Model saved to model_logistic_regression.pkl\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(max_iter=10000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_pred_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "lr_metrics = evaluate_model('Logistic Regression', y_test, lr_pred, lr_pred_proba)\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "for key, value in lr_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "with open('model_logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)\n",
    "print(\"\\nModel saved to model_logistic_regression.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Metrics:\n",
      "Accuracy: 0.9123\n",
      "Precision: 0.9559\n",
      "Recall: 0.9028\n",
      "F1: 0.9286\n",
      "MCC: 0.8174\n",
      "AUC: 0.9157\n",
      "\n",
      "Model saved to model_decision_tree.pkl\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_pred_proba = dt_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "dt_metrics = evaluate_model('Decision Tree', y_test, dt_pred, dt_pred_proba)\n",
    "print(\"Decision Tree Metrics:\")\n",
    "for key, value in dt_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "with open('model_decision_tree.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "print(\"\\nModel saved to model_decision_tree.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor Metrics:\n",
      "Accuracy: 0.9561\n",
      "Precision: 0.9589\n",
      "Recall: 0.9722\n",
      "F1: 0.9655\n",
      "MCC: 0.9054\n",
      "AUC: 0.9788\n",
      "\n",
      "Model saved to model_k-nearest_neighbor.pkl\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "knn_pred = knn_model.predict(X_test_scaled)\n",
    "knn_pred_proba = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "knn_metrics = evaluate_model('K-Nearest Neighbor', y_test, knn_pred, knn_pred_proba)\n",
    "print(\"K-Nearest Neighbor Metrics:\")\n",
    "for key, value in knn_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "with open('model_k-nearest_neighbor.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)\n",
    "print(\"\\nModel saved to model_k-nearest_neighbor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Naive Bayes Classifier (Gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Metrics:\n",
      "Accuracy: 0.9298\n",
      "Precision: 0.9444\n",
      "Recall: 0.9444\n",
      "F1: 0.9444\n",
      "MCC: 0.8492\n",
      "AUC: 0.9868\n",
      "\n",
      "Model saved to model_naive_bayes.pkl\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)\n",
    "nb_pred = nb_model.predict(X_test_scaled)\n",
    "nb_pred_proba = nb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "nb_metrics = evaluate_model('Naive Bayes', y_test, nb_pred, nb_pred_proba)\n",
    "print(\"Naive Bayes Metrics:\")\n",
    "for key, value in nb_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "with open('model_naive_bayes.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model, f)\n",
    "print(\"\\nModel saved to model_naive_bayes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Random Forest (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Accuracy: 0.9561\n",
      "Precision: 0.9589\n",
      "Recall: 0.9722\n",
      "F1: 0.9655\n",
      "MCC: 0.9054\n",
      "AUC: 0.9937\n",
      "\n",
      "Model saved to model_random_forest.pkl\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_metrics = evaluate_model('Random Forest', y_test, rf_pred, rf_pred_proba)\n",
    "print(\"Random Forest Metrics:\")\n",
    "for key, value in rf_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "with open('model_random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_model, f)\n",
    "print(\"\\nModel saved to model_random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 XGBoost (Ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Metrics:\n",
      "Accuracy: 0.9561\n",
      "Precision: 0.9467\n",
      "Recall: 0.9861\n",
      "F1: 0.9660\n",
      "MCC: 0.9058\n",
      "AUC: 0.9901\n",
      "\n",
      "Model saved to model_xgboost.pkl\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_metrics = evaluate_model('XGBoost', y_test, xgb_pred, xgb_pred_proba)\n",
    "print(\"XGBoost Metrics:\")\n",
    "for key, value in xgb_metrics.items():\n",
    "    if key != 'Model':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "with open('model_xgboost.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model, f)\n",
    "print(\"\\nModel saved to model_xgboost.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison of All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "================================================================================\n",
      "              Model  Accuracy      AUC  Precision   Recall       F1      MCC\n",
      "Logistic Regression  0.982456 0.995370   0.986111 0.986111 0.986111 0.962302\n",
      "      Decision Tree  0.912281 0.915675   0.955882 0.902778 0.928571 0.817412\n",
      " K-Nearest Neighbor  0.956140 0.978836   0.958904 0.972222 0.965517 0.905447\n",
      "        Naive Bayes  0.929825 0.986772   0.944444 0.944444 0.944444 0.849206\n",
      "      Random Forest  0.956140 0.993717   0.958904 0.972222 0.965517 0.905447\n",
      "            XGBoost  0.956140 0.990079   0.946667 0.986111 0.965986 0.905824\n",
      "\n",
      "Results saved to model_results.csv\n"
     ]
    }
   ],
   "source": [
    "all_metrics = [lr_metrics, dt_metrics, knn_metrics, nb_metrics, rf_metrics, xgb_metrics]\n",
    "results_df = pd.DataFrame(all_metrics)\n",
    "results_df = results_df[['Model', 'Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'MCC']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "results_df.to_csv('model_results.csv', index=False)\n",
    "print(\"\\nResults saved to model_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.995370</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.962302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.915675</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.817412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.978836</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.905447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.986772</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.849206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.993717</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.905447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.990079</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>0.905824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy       AUC  Precision    Recall        F1  \\\n",
       "0  Logistic Regression  0.982456  0.995370   0.986111  0.986111  0.986111   \n",
       "1        Decision Tree  0.912281  0.915675   0.955882  0.902778  0.928571   \n",
       "2   K-Nearest Neighbor  0.956140  0.978836   0.958904  0.972222  0.965517   \n",
       "3          Naive Bayes  0.929825  0.986772   0.944444  0.944444  0.944444   \n",
       "4        Random Forest  0.956140  0.993717   0.958904  0.972222  0.965517   \n",
       "5              XGBoost  0.956140  0.990079   0.946667  0.986111  0.965986   \n",
       "\n",
       "        MCC  \n",
       "0  0.962302  \n",
       "1  0.817412  \n",
       "2  0.905447  \n",
       "3  0.849206  \n",
       "4  0.905447  \n",
       "5  0.905824  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
